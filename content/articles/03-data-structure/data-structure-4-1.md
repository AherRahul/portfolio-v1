---
title: "Hash Tables & Hash Functions"
description: "Master constant-time data access. Learn hash function design, collision resolution techniques, load factors, and advanced hashing strategies for optimal performance."
slidesUrl: "https://github.com/AherRahul/portfolio-v1/blob/main/content/articles"
dateModified: "2025-09-26"
datePublished: "2025-09-26"
showOnArticles: false
courseName: 03-data-structure
topics:
  - data-structures
resources:
  - title: "Hash Table Visualizations"
    type: "tool"
    url: "https://visualgo.net/en/hashtable"
    description: "Interactive hash table operations and collision handling"
  - title: "Hash Function Analysis"
    type: "reference"
    url: "https://en.wikipedia.org/wiki/Hash_function"
    description: "Comprehensive guide to hash function design principles"
  - title: "Hash Table Problems"
    type: "practice"
    url: "https://leetcode.com/tag/hash-table/"
    description: "Practice problems for mastering hash table applications"

---

![image.png](https://res.cloudinary.com/duojkrgue/image/upload/v1758827456/Portfolio/dsa/images/15/hash_tables.png)

Hash Tables & Hash Functions ‚Äì Constant-Time Data Access Magic
==============================================================

Imagine you're the **head librarian of the world's largest library** üìö with **100 million books**, and patrons expect to find any book in **under 3 seconds**. Traditional methods would require checking millions of shelves, but you need **instant access**:

**üìö The Massive Library Challenge:**

**‚è∞ Traditional Book Finding Problems:**
- **Linear Search**: Must check every shelf one by one ‚Üí Could take **hours**
- **Alphabetical Sorting**: Still need to scan through thousands of books per letter
- **Category Organization**: Better but still requires extensive searching within categories
- **Index Systems**: Help but still involve multiple lookups and cross-references

**üîç The Reality Check:**
```
Finding "To Kill a Mockingbird" in 100 million books:
- Linear search: Average 50 million checks
- Binary search: ~27 comparisons (if perfectly sorted)
- Alphabetical: Still thousands of "T" books to check
- Even with best indexing: Multiple lookup steps required

Patron expectation: Find book in 3 seconds ‚è∞
Reality: Could take minutes or hours üò∞
```

**üéØ The Hash Table Solution (Magic Address System):**
Think of it like a **magical address system** where every book gets a **unique house number** calculated from its title. You don't search for the book‚Äîyou **calculate where it should be** and go directly there!

**üè† The Hash Address Magic:**
```
Step 1: Take book title "To Kill a Mockingbird"
Step 2: Apply magic formula (hash function):
        - Add ASCII values of characters
        - Apply some mathematical transformations
        - Result: Address #7,342,891

Step 3: Go directly to shelf #7,342,891
Step 4: Book is there! (or handle collision if another book is there)

Time taken: 1 calculation + 1 direct access = Instant! ‚ö°
```

**üîÆ The Hash Function (Address Calculator):**
```javascript
function magicalAddressCalculator(bookTitle) {
    let address = 0;
    for (let i = 0; i < bookTitle.length; i++) {
        address = (address * 31 + bookTitle.charCodeAt(i)) % 1000000;
    }
    return address; // Returns shelf number!
}

// Examples:
magicalAddressCalculator("Harry Potter") ‚Üí 42,397
magicalAddressCalculator("Lord of the Rings") ‚Üí 891,246
magicalAddressCalculator("1984") ‚Üí 156,789
```

**üìä The Performance Revolution:**
- **Traditional Search**: O(n) - could check all 100 million books
- **Hash Table Access**: O(1) - one calculation, one direct access
- **Space Trade-off**: Use extra space for direct addressing
- **Collision Handling**: What if two books calculate the same address?

**üöß The Collision Problem & Solutions:**

**Problem**: Sometimes different books calculate the same shelf address!
```
hash("Game of Thrones") ‚Üí 456,123
hash("Gone Girl") ‚Üí 456,123  // Same address! üò±
```

**Solution 1: Chaining (Multiple Books per Shelf)**
```
Shelf #456,123: [Box containing both books]
- Search inside box (small list)
- Still very fast since box contains only ~2-3 books on average
```

**Solution 2: Open Addressing (Find Next Available Shelf)**
```
Shelf #456,123: Already has "Game of Thrones"
Check #456,124: Empty! ‚Üí Place "Gone Girl" here
Remember: "Gone Girl" is at address+1, not exact address
```

**üìà The Hash Table Performance:**
- **Average Case**: O(1) - truly constant time access!
- **Worst Case**: O(n) - if all items hash to same address (very rare with good hash function)
- **Real World**: 99.9% of operations are O(1) with proper design
- **Load Factor**: Keep table ~70% full for optimal performance

**üåç Real-World Hash Table Applications:**
- **Databases**: Index structures for instant record lookup
- **Caching Systems**: Redis, Memcached for web application speed
- **Programming Languages**: Variable lookup tables in interpreters
- **Web Browsers**: DNS caching for website address resolution
- **Password Storage**: Secure password hashing and verification
- **Blockchain**: Proof-of-work systems and transaction verification
- **File Systems**: Inode tables for instant file metadata access

**üí° The Hash Table Magic Ingredients:**
1. **Hash Function**: Good "address calculator" that distributes evenly
2. **Collision Resolution**: Handle when multiple items get same address
3. **Dynamic Resizing**: Grow table when it gets too full
4. **Load Factor Management**: Keep table at optimal capacity

This is exactly how hash tables work in computer science! They transform **expensive searching operations** into **constant-time direct access**, making them the **foundation of modern computing performance**. From database indexes to web caches, hash tables make the impossible possible! üöÄ‚ú®

## The Theoretical Foundation: What Are Hash Tables? üèóÔ∏è

### Understanding Hash Table Mechanics

**A hash table is a data structure that implements an associative array abstract data type, where data is stored in an array format and each data value has its own unique index value.** The magic lies in the **hash function** - a mathematical formula that converts keys into array indices, enabling direct access to stored values.

**Core Hash Table Components:**

1. **Hash Function**: Converts keys to array indices (the "magic address calculator")
2. **Array/Bucket Structure**: Stores the actual key-value pairs
3. **Collision Resolution**: Handles when multiple keys map to same index
4. **Load Factor**: Ratio of stored elements to table capacity
5. **Dynamic Resizing**: Automatic table expansion when load factor exceeds threshold

**Hash Table Workflow:**
```
Key ‚Üí Hash Function ‚Üí Index ‚Üí Array[Index] ‚Üí Value

Example:
"apple" ‚Üí hash("apple") ‚Üí 42 ‚Üí table[42] ‚Üí "red fruit"
```

### Hash Function Properties

**Good Hash Function Characteristics:**

1. **Deterministic**: Same key always produces same hash value
2. **Uniform Distribution**: Spreads keys evenly across table
3. **Fast Computation**: Quick to calculate (typically O(1))
4. **Avalanche Effect**: Small input changes produce large output changes
5. **Low Collision Rate**: Minimizes keys mapping to same index

**Common Hash Function Techniques:**

**Division Method:**
```javascript
hash(key) = key % table_size
// Simple but table_size should be prime number
```

**Multiplication Method:**
```javascript
hash(key) = floor(table_size * ((key * A) % 1))
// Where A is constant ~0.6180339887 (golden ratio)
```

**Polynomial Rolling Hash:**
```javascript
hash(string) = (s[0] + s[1]*p + s[2]*p¬≤ + ... + s[n]*p^n) % m
// Where p is prime, m is table size
```

### Collision Resolution Strategies

**1. Separate Chaining (Open Hashing):**
- Each table slot contains a linked list of colliding elements
- **Advantages**: Simple implementation, handles high load factors well
- **Disadvantages**: Extra memory for pointers, potential cache misses

**2. Open Addressing (Closed Hashing):**
- All elements stored directly in table, find alternative slots for collisions
- **Linear Probing**: Check next slot sequentially
- **Quadratic Probing**: Check slots at quadratic intervals
- **Double Hashing**: Use second hash function for probe sequence

### Load Factor and Performance

**Load Factor (Œ±) = Number of Elements / Table Size**

**Performance Impact:**
- **Œ± < 0.7**: Excellent performance, low collision probability
- **Œ± = 0.7-0.8**: Good performance, reasonable collision rate
- **Œ± > 0.8**: Degrading performance, higher collision probability
- **Œ± > 1.0**: Poor performance (only possible with chaining)

**Dynamic Resizing Triggers:**
- **Expand**: When load factor exceeds 0.75 (typically double size)
- **Shrink**: When load factor falls below 0.25 (typically halve size)

## Hash Table Implementation üîß

**Concept**: Complete hash table implementation with multiple collision resolution strategies.

```javascript
// Complete Hash Table Implementation with Collision Resolution

class HashTable {
    constructor(initialCapacity = 16, loadFactorThreshold = 0.75) {
        this.capacity = initialCapacity;
        this.size = 0;
        this.loadFactorThreshold = loadFactorThreshold;
        this.buckets = new Array(this.capacity).fill(null);
        this.collisionCount = 0;
        this.resizeCount = 0;
        
        // Statistics tracking
        this.insertions = 0;
        this.lookups = 0;
        this.deletions = 0;
    }
    
    // Primary hash function (polynomial rolling hash)
    hash(key) {
        if (typeof key !== 'string') {
            key = String(key);
        }
        
        let hash = 0;
        const prime = 31; // Good prime for string hashing
        
        for (let i = 0; i < key.length; i++) {
            hash = (hash * prime + key.charCodeAt(i)) % this.capacity;
        }
        
        return Math.abs(hash); // Ensure positive index
    }
    
    // Secondary hash function (for double hashing)
    hash2(key) {
        if (typeof key !== 'string') {
            key = String(key);
        }
        
        let hash = 0;
        const prime = 37; // Different prime
        
        for (let i = 0; i < key.length; i++) {
            hash = (hash * prime + key.charCodeAt(i)) % (this.capacity - 1);
        }
        
        return Math.abs(hash) + 1; // Ensure non-zero step
    }
    
    // Calculate current load factor
    getLoadFactor() {
        return this.size / this.capacity;
    }
    
    // Set key-value pair - O(1) average case
    set(key, value) {
        console.log(`\nüìù SETTING: "${key}" ‚Üí "${value}"`);
        console.log(`Current state: size=${this.size}, capacity=${this.capacity}, load=${this.getLoadFactor().toFixed(3)}`);
        
        this.insertions++;
        
        // Check if resize needed before insertion
        if (this.getLoadFactor() >= this.loadFactorThreshold) {
            console.log(`‚ö†Ô∏è Load factor ${this.getLoadFactor().toFixed(3)} exceeds threshold ${this.loadFactorThreshold}`);
            this.resize(this.capacity * 2);
        }
        
        const index = this.hash(key);
        console.log(`Hash calculation: hash("${key}") = ${index}`);
        
        // Check if bucket is empty
        if (this.buckets[index] === null) {
            console.log(`‚úÖ Empty bucket at index ${index} - direct insertion`);
            this.buckets[index] = [{ key, value }]; // Chaining: start with array
            this.size++;
        } else {
            console.log(`‚ö†Ô∏è Collision detected at index ${index}`);
            this.collisionCount++;
            
            // Handle collision using separate chaining
            const bucket = this.buckets[index];
            console.log(`Current bucket contents: ${bucket.map(item => `${item.key}:${item.value}`).join(', ')}`);
            
            // Check if key already exists (update case)
            const existingIndex = bucket.findIndex(item => item.key === key);
            
            if (existingIndex !== -1) {
                console.log(`üîÑ Updating existing key "${key}"`);
                console.log(`Old value: "${bucket[existingIndex].value}" ‚Üí New value: "${value}"`);
                bucket[existingIndex].value = value;
            } else {
                console.log(`‚ûï Adding new key-value pair to bucket`);
                bucket.push({ key, value });
                this.size++;
            }
            
            console.log(`Updated bucket: ${bucket.map(item => `${item.key}:${item.value}`).join(', ')}`);
        }
        
        console.log(`‚úÖ Set complete. New size: ${this.size}, load factor: ${this.getLoadFactor().toFixed(3)}`);
        console.log(`Total collisions so far: ${this.collisionCount}`);
        
        return this;
    }
    
    // Get value by key - O(1) average case
    get(key) {
        console.log(`\nüîç GETTING: "${key}"`);
        
        this.lookups++;
        
        const index = this.hash(key);
        console.log(`Hash calculation: hash("${key}") = ${index}`);
        
        const bucket = this.buckets[index];
        
        if (bucket === null) {
            console.log(`‚ùå Bucket ${index} is empty - key not found`);
            console.log(`Time Complexity: O(1) - direct access to empty bucket`);
            return undefined;
        }
        
        console.log(`üîç Searching in bucket: ${bucket.map(item => `${item.key}:${item.value}`).join(', ')}`);
        
        // Linear search within bucket (due to collision chaining)
        for (let i = 0; i < bucket.length; i++) {
            const item = bucket[i];
            console.log(`  Checking item ${i + 1}: "${item.key}"`);
            
            if (item.key === key) {
                console.log(`‚úÖ Key "${key}" found with value "${item.value}"`);
                console.log(`Bucket search steps: ${i + 1}`);
                console.log(`Time Complexity: O(1 + bucket_size) - average bucket size is very small`);
                return item.value;
            }
        }
        
        console.log(`‚ùå Key "${key}" not found in bucket`);
        console.log(`Searched ${bucket.length} items in bucket`);
        return undefined;
    }
    
    // Check if key exists - O(1) average case
    has(key) {
        console.log(`\n‚ùì CHECKING existence of: "${key}"`);
        
        const value = this.get(key);
        const exists = value !== undefined;
        
        console.log(`Result: Key "${key}" ${exists ? 'EXISTS' : 'DOES NOT EXIST'}`);
        return exists;
    }
    
    // Delete key-value pair - O(1) average case
    delete(key) {
        console.log(`\nüóëÔ∏è DELETING: "${key}"`);
        
        this.deletions++;
        
        const index = this.hash(key);
        console.log(`Hash calculation: hash("${key}") = ${index}`);
        
        const bucket = this.buckets[index];
        
        if (bucket === null) {
            console.log(`‚ùå Bucket ${index} is empty - key not found`);
            return false;
        }
        
        console.log(`üîç Searching in bucket: ${bucket.map(item => `${item.key}:${item.value}`).join(', ')}`);
        
        // Find and remove key
        for (let i = 0; i < bucket.length; i++) {
            const item = bucket[i];
            
            if (item.key === key) {
                console.log(`‚úÖ Found key "${key}" with value "${item.value}" at position ${i}`);
                
                // Remove item from bucket
                bucket.splice(i, 1);
                this.size--;
                
                console.log(`üóëÔ∏è Removed item. Bucket now: ${bucket.map(item => `${item.key}:${item.value}`).join(', ') || 'EMPTY'}`);
                
                // Clean up empty bucket
                if (bucket.length === 0) {
                    this.buckets[index] = null;
                    console.log(`üßπ Bucket is now empty - cleaned up`);
                }
                
                console.log(`‚úÖ Deletion complete. New size: ${this.size}`);
                
                // Check if resize needed (shrink)
                if (this.size > 0 && this.getLoadFactor() < 0.25 && this.capacity > 16) {
                    console.log(`üìâ Load factor ${this.getLoadFactor().toFixed(3)} below 0.25 - considering shrink`);
                    this.resize(Math.max(16, Math.floor(this.capacity / 2)));
                }
                
                return true;
            }
        }
        
        console.log(`‚ùå Key "${key}" not found for deletion`);
        return false;
    }
    
    // Resize hash table to maintain performance
    resize(newCapacity) {
        console.log(`\nüîÑ RESIZING: ${this.capacity} ‚Üí ${newCapacity}`);
        console.log(`Reason: Load factor = ${this.getLoadFactor().toFixed(3)}`);
        
        this.resizeCount++;
        
        // Store old data
        const oldBuckets = this.buckets;
        const oldCapacity = this.capacity;
        
        // Create new table
        this.capacity = newCapacity;
        this.buckets = new Array(this.capacity).fill(null);
        const oldSize = this.size;
        this.size = 0; // Reset size, will be incremented during re-insertion
        
        console.log(`Created new table with capacity ${newCapacity}`);
        console.log(`Rehashing ${oldSize} items...`);
        
        let rehashedItems = 0;
        
        // Rehash all existing items
        for (let i = 0; i < oldCapacity; i++) {
            const bucket = oldBuckets[i];
            
            if (bucket !== null) {
                console.log(`  Rehashing bucket ${i}: ${bucket.length} items`);
                
                for (const item of bucket) {
                    console.log(`    Rehashing: "${item.key}" ‚Üí "${item.value}"`);
                    
                    // Use internal set logic without resize check
                    const newIndex = this.hash(item.key);
                    
                    if (this.buckets[newIndex] === null) {
                        this.buckets[newIndex] = [{ key: item.key, value: item.value }];
                    } else {
                        this.buckets[newIndex].push({ key: item.key, value: item.value });
                    }
                    
                    this.size++;
                    rehashedItems++;
                    console.log(`      New location: index ${newIndex}`);
                }
            }
        }
        
        console.log(`‚úÖ Resize complete!`);
        console.log(`Rehashed ${rehashedItems} items from ${oldCapacity} to ${newCapacity} buckets`);
        console.log(`New load factor: ${this.getLoadFactor().toFixed(3)}`);
        console.log(`Total resizes in lifetime: ${this.resizeCount}`);
    }
    
    // Get all keys
    keys() {
        console.log(`\nüîë GETTING all keys`);
        const allKeys = [];
        
        for (let i = 0; i < this.capacity; i++) {
            const bucket = this.buckets[i];
            
            if (bucket !== null) {
                for (const item of bucket) {
                    allKeys.push(item.key);
                }
            }
        }
        
        console.log(`Found ${allKeys.length} keys: [${allKeys.join(', ')}]`);
        return allKeys;
    }
    
    // Get all values
    values() {
        console.log(`\nüíé GETTING all values`);
        const allValues = [];
        
        for (let i = 0; i < this.capacity; i++) {
            const bucket = this.buckets[i];
            
            if (bucket !== null) {
                for (const item of bucket) {
                    allValues.push(item.value);
                }
            }
        }
        
        console.log(`Found ${allValues.length} values: [${allValues.join(', ')}]`);
        return allValues;
    }
    
    // Get all key-value pairs
    entries() {
        console.log(`\nüìã GETTING all entries`);
        const allEntries = [];
        
        for (let i = 0; i < this.capacity; i++) {
            const bucket = this.buckets[i];
            
            if (bucket !== null) {
                for (const item of bucket) {
                    allEntries.push([item.key, item.value]);
                }
            }
        }
        
        console.log(`Found ${allEntries.length} entries`);
        allEntries.forEach(([key, value], index) => {
            console.log(`  ${index + 1}. "${key}" ‚Üí "${value}"`);
        });
        
        return allEntries;
    }
    
    // Clear all data
    clear() {
        console.log(`\nüßπ CLEARING hash table`);
        console.log(`Removing ${this.size} items from ${this.capacity} buckets`);
        
        this.buckets = new Array(this.capacity).fill(null);
        this.size = 0;
        
        console.log(`‚úÖ Hash table cleared`);
    }
    
    // Display hash table statistics
    displayStats() {
        console.log(`\nüìä HASH TABLE STATISTICS`);
        console.log(`========================`);
        console.log(`Size: ${this.size} items`);
        console.log(`Capacity: ${this.capacity} buckets`);
        console.log(`Load Factor: ${this.getLoadFactor().toFixed(3)} (${(this.getLoadFactor() * 100).toFixed(1)}%)`);
        console.log(`Collisions: ${this.collisionCount}`);
        console.log(`Resizes: ${this.resizeCount}`);
        console.log(`Operations: ${this.insertions} sets, ${this.lookups} gets, ${this.deletions} deletes`);
        
        // Bucket distribution analysis
        let emptyBuckets = 0;
        let maxBucketSize = 0;
        let totalChainLength = 0;
        const bucketSizes = [];
        
        for (let i = 0; i < this.capacity; i++) {
            const bucket = this.buckets[i];
            
            if (bucket === null) {
                emptyBuckets++;
                bucketSizes.push(0);
            } else {
                const bucketSize = bucket.length;
                bucketSizes.push(bucketSize);
                maxBucketSize = Math.max(maxBucketSize, bucketSize);
                totalChainLength += bucketSize;
            }
        }
        
        const avgChainLength = this.size > 0 ? (totalChainLength / (this.capacity - emptyBuckets)).toFixed(2) : 0;
        
        console.log(`\nüîó BUCKET DISTRIBUTION:`);
        console.log(`Empty buckets: ${emptyBuckets}/${this.capacity} (${(emptyBuckets/this.capacity*100).toFixed(1)}%)`);
        console.log(`Used buckets: ${this.capacity - emptyBuckets}/${this.capacity} (${((this.capacity-emptyBuckets)/this.capacity*100).toFixed(1)}%)`);
        console.log(`Max bucket size: ${maxBucketSize} items`);
        console.log(`Avg chain length: ${avgChainLength} items per used bucket`);
        
        // Show distribution histogram
        const maxDisplay = Math.min(10, maxBucketSize);
        console.log(`\nBucket size distribution:`);
        for (let size = 0; size <= maxDisplay; size++) {
            const count = bucketSizes.filter(s => s === size).length;
            const percentage = (count / this.capacity * 100).toFixed(1);
            const bar = '‚ñà'.repeat(Math.floor(count / this.capacity * 50));
            console.log(`  Size ${size}: ${count.toString().padStart(3)} buckets (${percentage.padStart(5)}%) ${bar}`);
        }
        
        if (maxBucketSize > maxDisplay) {
            const largeCount = bucketSizes.filter(s => s > maxDisplay).length;
            console.log(`  Size >${maxDisplay}: ${largeCount} buckets`);
        }
        
        console.log(`\n‚ö° PERFORMANCE ANALYSIS:`);
        if (this.getLoadFactor() < 0.5) {
            console.log(`‚úÖ Excellent performance - low load factor, minimal collisions`);
        } else if (this.getLoadFactor() < 0.75) {
            console.log(`‚úÖ Good performance - moderate load factor, acceptable collisions`);
        } else if (this.getLoadFactor() < 0.9) {
            console.log(`‚ö†Ô∏è Fair performance - high load factor, increased collisions`);
        } else {
            console.log(`‚ùå Poor performance - very high load factor, many collisions`);
        }
        
        if (maxBucketSize <= 3) {
            console.log(`‚úÖ Good hash function distribution - small bucket chains`);
        } else if (maxBucketSize <= 5) {
            console.log(`‚ö†Ô∏è Fair hash function distribution - moderate bucket chains`);
        } else {
            console.log(`‚ùå Poor hash function distribution - large bucket chains`);
        }
    }
    
    // Visualize hash table structure
    visualizeStructure() {
        console.log(`\nüóÇÔ∏è HASH TABLE STRUCTURE`);
        console.log(`========================`);
        
        const maxDisplay = Math.min(20, this.capacity);
        
        for (let i = 0; i < maxDisplay; i++) {
            const bucket = this.buckets[i];
            let bucketDisplay = `[${i.toString().padStart(3)}] `;
            
            if (bucket === null) {
                bucketDisplay += '‚àÖ (empty)';
            } else {
                const items = bucket.map(item => `${item.key}:${item.value}`);
                bucketDisplay += `[${items.join(' ‚Üí ')}]`;
                
                if (bucket.length > 1) {
                    bucketDisplay += ` ‚ö†Ô∏è (${bucket.length} items - collision)`;
                }
            }
            
            console.log(bucketDisplay);
        }
        
        if (this.capacity > maxDisplay) {
            console.log(`... (${this.capacity - maxDisplay} more buckets)`);
        }
        
        console.log(`\nLegend:`);
        console.log(`‚àÖ = Empty bucket`);
        console.log(`[key:value] = Single item in bucket`);
        console.log(`[key1:value1 ‚Üí key2:value2] = Chain due to collision`);
        console.log(`‚ö†Ô∏è = Collision occurred (multiple items in same bucket)`);
    }
    
    // Demonstrate hash table operations
    demonstrateHashTable() {
        console.log('=== HASH TABLE DEMONSTRATION ===\n');
        
        console.log('1. BASIC HASH TABLE OPERATIONS:');
        this.set('apple', 'red fruit');
        this.set('banana', 'yellow fruit');
        this.set('grape', 'purple fruit');
        this.set('orange', 'orange fruit');
        
        this.displayStats();
        this.visualizeStructure();
        
        console.log('\n2. HASH COLLISION DEMONSTRATION:');
        // Force some collisions by adding more items
        this.set('cherry', 'red small fruit');
        this.set('kiwi', 'green fuzzy fruit');
        this.set('mango', 'tropical fruit');
        this.set('peach', 'soft orange fruit');
        
        this.displayStats();
        
        console.log('\n3. LOOKUP OPERATIONS:');
        ['apple', 'banana', 'strawberry', 'grape'].forEach(key => {
            this.get(key);
        });
        
        console.log('\n4. UPDATE OPERATIONS:');
        this.set('apple', 'crunchy red fruit'); // Update existing
        this.get('apple');
        
        console.log('\n5. DELETION OPERATIONS:');
        this.delete('banana');
        this.delete('strawberry'); // Non-existent
        
        console.log('\n6. ITERATION OPERATIONS:');
        this.keys();
        this.values();
        this.entries();
        
        console.log('\n7. RESIZE DEMONSTRATION:');
        console.log('Adding many items to trigger resize...');
        
        for (let i = 0; i < 20; i++) {
            this.set(`item${i}`, `value${i}`);
        }
        
        this.displayStats();
        
        console.log('\n8. FINAL STATE:');
        console.log(`Final size: ${this.size} items`);
        console.log(`Final capacity: ${this.capacity} buckets`);
        console.log(`Final load factor: ${this.getLoadFactor().toFixed(3)}`);
        
        console.log(`\nüéØ HASH TABLE SUMMARY:`);
        console.log(`- Average O(1) time complexity for all operations`);
        console.log(`- Automatic resizing maintains optimal performance`);
        console.log(`- Collision resolution ensures correctness`);
        console.log(`- Space-time tradeoff: uses extra space for speed`);
        console.log(`- Foundation of many higher-level data structures`);
        console.log(`- Essential for caches, databases, and language implementations`);
        
        return {
            size: this.size,
            capacity: this.capacity,
            loadFactor: this.getLoadFactor(),
            collisions: this.collisionCount,
            resizes: this.resizeCount
        };
    }
}

// Test hash table operations
const hashTable = new HashTable();
hashTable.demonstrateHashTable();
```

### Hash Function Analysis & Design

**Concept**: Understanding different hash function strategies and their trade-offs.

```javascript
// Hash Function Analysis and Comparison

class HashFunctionAnalyzer {
    constructor() {
        this.testData = [
            'apple', 'banana', 'cherry', 'date', 'elderberry',
            'fig', 'grape', 'honeydew', 'kiwi', 'lemon',
            'mango', 'nectarine', 'orange', 'papaya', 'quince',
            'raspberry', 'strawberry', 'tangerine', 'ugli', 'vanilla'
        ];
        this.tableSize = 13; // Prime number for better distribution
    }
    
    // Simple hash function - division method
    simpleHash(key) {
        let sum = 0;
        for (let i = 0; i < key.length; i++) {
            sum += key.charCodeAt(i);
        }
        return sum % this.tableSize;
    }
    
    // Better hash function - polynomial rolling hash
    polynomialHash(key) {
        let hash = 0;
        const prime = 31;
        
        for (let i = 0; i < key.length; i++) {
            hash = (hash * prime + key.charCodeAt(i)) % this.tableSize;
        }
        
        return Math.abs(hash);
    }
    
    // DJB2 hash function (popular in practice)
    djb2Hash(key) {
        let hash = 5381;
        
        for (let i = 0; i < key.length; i++) {
            hash = ((hash << 5) + hash + key.charCodeAt(i)) % this.tableSize;
        }
        
        return Math.abs(hash);
    }
    
    // FNV-1a hash function (fast and good distribution)
    fnv1aHash(key) {
        let hash = 2166136261; // FNV offset basis
        
        for (let i = 0; i < key.length; i++) {
            hash ^= key.charCodeAt(i);
            hash *= 16777619; // FNV prime
        }
        
        return Math.abs(hash) % this.tableSize;
    }
    
    // Analyze hash function distribution
    analyzeHashFunction(hashFunction, functionName) {
        console.log(`\nüìä ANALYZING: ${functionName}`);
        console.log(`Table size: ${this.tableSize}`);
        console.log(`Test data: ${this.testData.length} items`);
        
        // Calculate hash values for all test data
        const hashValues = this.testData.map(item => hashFunction.call(this, item));
        const distribution = new Array(this.tableSize).fill(0);
        
        // Count items per bucket
        hashValues.forEach(hash => distribution[hash]++);
        
        console.log(`\nHash values:`);
        this.testData.forEach((item, index) => {
            console.log(`  "${item}" ‚Üí ${hashValues[index]}`);
        });
        
        console.log(`\nDistribution analysis:`);
        let collisions = 0;
        let emptyBuckets = 0;
        let maxBucketSize = 0;
        
        for (let i = 0; i < this.tableSize; i++) {
            const count = distribution[i];
            maxBucketSize = Math.max(maxBucketSize, count);
            
            if (count === 0) {
                emptyBuckets++;
            } else if (count > 1) {
                collisions += count - 1; // Each extra item is a collision
            }
            
            const bar = '‚ñà'.repeat(count);
            console.log(`  Bucket ${i.toString().padStart(2)}: ${count} items ${bar}`);
        }
        
        // Calculate statistics
        const loadFactor = this.testData.length / this.tableSize;
        const uniformityScore = this.calculateUniformityScore(distribution);
        
        console.log(`\nüìà Statistics:`);
        console.log(`  Load factor: ${loadFactor.toFixed(3)}`);
        console.log(`  Collisions: ${collisions} (${(collisions/this.testData.length*100).toFixed(1)}%)`);
        console.log(`  Empty buckets: ${emptyBuckets}/${this.tableSize} (${(emptyBuckets/this.tableSize*100).toFixed(1)}%)`);
        console.log(`  Max bucket size: ${maxBucketSize} items`);
        console.log(`  Uniformity score: ${uniformityScore.toFixed(3)} (1.0 = perfect)`);
        
        // Performance assessment
        console.log(`\n‚ö° Performance assessment:`);
        if (collisions === 0) {
            console.log(`  üåü EXCELLENT: No collisions - perfect distribution!`);
        } else if (collisions <= this.testData.length * 0.1) {
            console.log(`  ‚úÖ GOOD: Low collision rate - excellent performance`);
        } else if (collisions <= this.testData.length * 0.3) {
            console.log(`  ‚ö†Ô∏è FAIR: Moderate collision rate - acceptable performance`);
        } else {
            console.log(`  ‚ùå POOR: High collision rate - poor performance`);
        }
        
        return {
            collisions,
            emptyBuckets,
            maxBucketSize,
            uniformityScore,
            distribution
        };
    }
    
    // Calculate uniformity score (how evenly distributed)
    calculateUniformityScore(distribution) {
        const expectedItemsPerBucket = this.testData.length / this.tableSize;
        let totalDeviation = 0;
        
        for (let count of distribution) {
            totalDeviation += Math.abs(count - expectedItemsPerBucket);
        }
        
        const maxPossibleDeviation = this.testData.length;
        return 1 - (totalDeviation / (2 * maxPossibleDeviation));
    }
    
    // Compare all hash functions
    compareHashFunctions() {
        console.log('=== HASH FUNCTION COMPARISON ===');
        
        const results = {};
        
        // Test each hash function
        results.simple = this.analyzeHashFunction(this.simpleHash, 'Simple Hash (Sum % Size)');
        results.polynomial = this.analyzeHashFunction(this.polynomialHash, 'Polynomial Rolling Hash');
        results.djb2 = this.analyzeHashFunction(this.djb2Hash, 'DJB2 Hash');
        results.fnv1a = this.analyzeHashFunction(this.fnv1aHash, 'FNV-1a Hash');
        
        // Summary comparison
        console.log(`\nüèÜ COMPARISON SUMMARY:`);
        console.log(`${'Function'.padEnd(25)} ${'Collisions'.padEnd(12)} ${'Empty'.padEnd(8)} ${'Max Size'.padEnd(10)} ${'Uniformity'.padEnd(12)}`);
        console.log(`${'='.repeat(25)} ${'='.repeat(12)} ${'='.repeat(8)} ${'='.repeat(10)} ${'='.repeat(12)}`);
        
        Object.entries(results).forEach(([name, result]) => {
            const displayName = name.charAt(0).toUpperCase() + name.slice(1);
            console.log(
                `${displayName.padEnd(25)} ` +
                `${result.collisions.toString().padEnd(12)} ` +
                `${result.emptyBuckets.toString().padEnd(8)} ` +
                `${result.maxBucketSize.toString().padEnd(10)} ` +
                `${result.uniformityScore.toFixed(3).padEnd(12)}`
            );
        });
        
        // Recommendations
        console.log(`\nüí° RECOMMENDATIONS:`);
        console.log(`ü•á Best overall: Polynomial Rolling Hash or DJB2`);
        console.log(`‚ö° Fastest: Simple Hash (but poor distribution)`);
        console.log(`üéØ Most uniform: FNV-1a (excellent for large datasets)`);
        console.log(`üìö Educational: Simple Hash (easy to understand)`);
        
        return results;
    }
    
    // Demonstrate hash function properties
    demonstrateHashProperties() {
        console.log('\n=== HASH FUNCTION PROPERTIES DEMO ===');
        
        console.log('\n1. DETERMINISTIC PROPERTY:');
        const testKey = 'apple';
        console.log(`Testing key: "${testKey}"`);
        
        for (let i = 0; i < 3; i++) {
            const hash1 = this.polynomialHash(testKey);
            const hash2 = this.polynomialHash(testKey);
            console.log(`  Attempt ${i + 1}: ${hash1} === ${hash2} ‚Üí ${hash1 === hash2 ? '‚úÖ' : '‚ùå'}`);
        }
        
        console.log('\n2. AVALANCHE EFFECT:');
        const baseKey = 'hello';
        const variants = ['hello', 'Hello', 'hello!', 'helloworld', 'hell'];
        
        console.log(`Testing variations of: "${baseKey}"`);
        variants.forEach(variant => {
            const hash = this.polynomialHash(variant);
            console.log(`  "${variant}" ‚Üí ${hash}`);
        });
        
        console.log('\n3. UNIFORM DISTRIBUTION TEST:');
        console.log('Testing with different data sets...');
        
        // Test with numbers
        const numberStrings = Array.from({length: 20}, (_, i) => i.toString());
        this.analyzeDataSet(numberStrings, 'Sequential Numbers');
        
        // Test with similar strings
        const similarStrings = Array.from({length: 10}, (_, i) => `test${i}`);
        this.analyzeDataSet(similarStrings, 'Similar Strings');
        
        return true;
    }
    
    analyzeDataSet(dataSet, description) {
        console.log(`\nüîç Analyzing: ${description}`);
        console.log(`Data: [${dataSet.join(', ')}]`);
        
        const hashes = dataSet.map(item => this.polynomialHash(item));
        const distribution = new Array(this.tableSize).fill(0);
        
        hashes.forEach(hash => distribution[hash]++);
        
        const collisions = hashes.length - new Set(hashes).size;
        const emptyBuckets = distribution.filter(count => count === 0).length;
        
        console.log(`  Collisions: ${collisions}/${dataSet.length} items`);
        console.log(`  Empty buckets: ${emptyBuckets}/${this.tableSize} buckets`);
        console.log(`  Distribution: [${distribution.join(', ')}]`);
    }
    
    // Performance testing
    performanceTest() {
        console.log('\n=== HASH FUNCTION PERFORMANCE TEST ===');
        
        const iterations = 100000;
        const testKey = 'performance_test_string_12345';
        
        console.log(`Testing ${iterations} iterations with key: "${testKey}"`);
        
        const functions = [
            { name: 'Simple Hash', func: this.simpleHash },
            { name: 'Polynomial Hash', func: this.polynomialHash },
            { name: 'DJB2 Hash', func: this.djb2Hash },
            { name: 'FNV-1a Hash', func: this.fnv1aHash }
        ];
        
        functions.forEach(({ name, func }) => {
            const startTime = performance.now();
            
            for (let i = 0; i < iterations; i++) {
                func.call(this, testKey);
            }
            
            const endTime = performance.now();
            const totalTime = (endTime - startTime).toFixed(3);
            const avgTime = ((endTime - startTime) / iterations * 1000).toFixed(6);
            
            console.log(`${name.padEnd(20)}: ${totalTime}ms total, ${avgTime}Œºs per hash`);
        });
        
        console.log(`\nüí° Performance insights:`);
        console.log(`- Simple operations (addition) are fastest`);
        console.log(`- Multiplication and shifts add some overhead`);
        console.log(`- XOR operations (FNV-1a) are very fast`);
        console.log(`- All functions are extremely fast for practical use`);
        
        return true;
    }
}

// Test hash function analysis
console.log('\n' + '='.repeat(60));
const analyzer = new HashFunctionAnalyzer();
analyzer.compareHashFunctions();
analyzer.demonstrateHashProperties();
analyzer.performanceTest();
```

## Summary

### Core Hash Table Concepts Mastered
- **Hash Function**: Mathematical transformation converting keys to array indices
- **Collision Resolution**: Handling multiple keys mapping to same index (chaining/open addressing)
- **Load Factor**: Ratio optimization for maintaining O(1) performance
- **Dynamic Resizing**: Automatic table expansion/contraction for optimal performance

### Hash Table Operations Complexity
- **Search**: O(1) average case, O(n) worst case (all items hash to same bucket)
- **Insert**: O(1) average case, O(n) worst case (resize operation)
- **Delete**: O(1) average case, O(n) worst case (worst-case collision chain)
- **Space**: O(n) - requires extra space for sparse array storage

### Why Hash Tables Are Essential
- **Constant-Time Access**: Average O(1) performance for all basic operations
- **Versatile Foundation**: Building block for sets, maps, caches, databases
- **Real-World Performance**: Predictable performance in practical applications
- **Memory-Speed Tradeoff**: Use extra space to achieve dramatic speed improvements

### Hash Function Design Principles

**Good Hash Function Properties:**
- **Deterministic**: Same input always produces same output
- **Uniform Distribution**: Spreads keys evenly across table
- **Avalanche Effect**: Small input changes cause large output changes
- **Fast Computation**: Quick to calculate, typically O(key_length)
- **Low Collision Rate**: Minimizes keys mapping to same index

**Common Hash Function Types:**
- **Division Method**: Simple modulo operation (hash = key % table_size)
- **Multiplication Method**: Uses golden ratio for better distribution
- **Polynomial Rolling**: Excellent for strings (a‚ÇÄ + a‚ÇÅp + a‚ÇÇp¬≤ + ...)
- **Cryptographic Hashes**: Strong security but slower (SHA-256, MD5)

### Collision Resolution Strategies

**Separate Chaining (Open Hashing):**
- **Approach**: Each table slot contains linked list of colliding elements
- **Advantages**: Simple implementation, handles high load factors well
- **Disadvantages**: Extra memory for pointers, potential cache misses
- **Best for**: High load factors, unknown data size

**Open Addressing (Closed Hashing):**
- **Linear Probing**: Check next slot sequentially (simple but clustering)
- **Quadratic Probing**: Check slots at quadratic intervals (reduces clustering)
- **Double Hashing**: Use second hash function for probe sequence (best distribution)
- **Advantages**: Better cache locality, no pointer overhead
- **Disadvantages**: Performance degrades with high load factors

### Real-World Hash Table Applications

**Database Systems:**
- **Index Structures**: B-tree leaves often use hash tables for fast lookups
- **Query Optimization**: Hash joins for efficient table merging
- **Transaction Management**: Lock tables and transaction logs

**Caching Systems:**
- **Web Caches**: Browser caches, CDN content distribution
- **Application Caches**: Redis, Memcached for database query caching
- **CPU Caches**: Hardware translation lookaside buffers (TLBs)

**Programming Languages:**
- **Symbol Tables**: Variable and function name resolution in compilers
- **Object Properties**: JavaScript objects, Python dictionaries
- **Module Systems**: Import/export resolution and dependency management

**Network Infrastructure:**
- **DNS Resolution**: Domain name to IP address mapping
- **Router Tables**: Network packet forwarding decisions
- **Load Balancing**: Request distribution across server clusters

### Performance Optimization Techniques

**Load Factor Management:**
- **Optimal Range**: Keep load factor between 0.5-0.75 for best performance
- **Resize Triggers**: Expand at 0.75, shrink at 0.25 load factor
- **Resize Strategy**: Double/halve size to amortize resize costs

**Hash Function Selection:**
- **String Keys**: Polynomial rolling hash or DJB2 for good distribution
- **Integer Keys**: Multiplication method or simple modulo with prime table size
- **Custom Objects**: Combine hash codes of object fields

**Memory Layout Optimization:**
- **Cache Locality**: Store key-value pairs together in memory
- **Robin Hood Hashing**: Minimize variance in probe distances
- **Hopscotch Hashing**: Maintain locality while supporting high load factors

### Advanced Hash Table Concepts

**Consistent Hashing:**
- **Distributed Systems**: Minimize rehashing when nodes added/removed
- **Load Balancing**: Evenly distribute requests across servers
- **Caching**: Reduce cache invalidation in distributed caches

**Cuckoo Hashing:**
- **Worst-Case Guarantees**: O(1) worst-case lookup time
- **Two Hash Functions**: Each key has two possible locations
- **Eviction Process**: Displace existing items to make room for new ones

**Bloom Filters:**
- **Probabilistic**: Space-efficient approximate membership testing
- **False Positives**: May say item exists when it doesn't
- **No False Negatives**: If says item doesn't exist, it definitely doesn't

### Hash Table Implementation Patterns

**Language-Specific Implementations:**
- **JavaScript**: Objects and Maps use hash tables internally
- **Python**: Dictionaries use open addressing with random probing
- **Java**: HashMap uses separate chaining with tree conversion for large buckets
- **C++**: unordered_map typically uses separate chaining

**Thread Safety Considerations:**
- **Concurrent Access**: Use locks or lock-free algorithms for thread safety
- **Read-Heavy Workloads**: Reader-writer locks for better read performance
- **High Contention**: Consider specialized concurrent hash table implementations

Hash tables represent the **ultimate performance optimization** in computer science - trading space for time to achieve constant-time access to data. They're the **foundation of modern computing performance**, powering everything from programming language implementations to distributed database systems! üöÄ‚ú®

Next up: **Sets & Advanced Set Operations** - Learn mathematical set operations, union-find data structures, and efficient membership testing!

<function_calls>
<invoke name="todo_write">
<parameter name="merge">true
